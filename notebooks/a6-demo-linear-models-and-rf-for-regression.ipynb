{"cells":[{"metadata":{"_uuid":"fa68e17d12b944b5925f0f1f3b35de84f88b63e7"},"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\">\n## Open Machine Learning Course\n<center>Author: [Yury Kashnitsky](https://www.linkedin.com/in/festline/), Data Scientist at Mail.ru Group <br>\n    All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.\nYou may use this material for any purpose (you can edit, correct and use it as example) exept commercial use with mandatory citation of author."},{"metadata":{"_uuid":"d4fba24c2fc97c5651c8b229a864bd3e4fb9c80a"},"cell_type":"markdown","source":"# <center> Assignment #6 (demo).\n## <center>  Exploring OLS, Lasso and Random Forest in a regression task\n    \n<img src=https://habrastorage.org/webt/-h/ns/aa/-hnsaaifymavmmudwip9imcmk58.jpeg width=30%>\n\n**Fill in the missing code and choose answers in [this](https://docs.google.com/forms/d/1aHyK58W6oQmNaqEfvpLTpo6Cb0-ntnvJ18rZcvclkvw/edit) web form.**"},{"metadata":{"trusted":true,"_uuid":"5a5dbe8ccaac5938472fffabd662570bbee580a5"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics.regression import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.linear_model import LinearRegression, LassoCV, Lasso\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"42c346b2e75d1f1aad91a95e17994c541657c4e5"},"cell_type":"markdown","source":"**We are working with UCI Wine quality dataset (no need to download it – it's already there, in course repo and in Kaggle Dataset).**"},{"metadata":{"trusted":true,"_uuid":"6fbd38aed5fa42e075b5d5a33e8e2da21807ad75"},"cell_type":"code","source":"data = pd.read_csv('../input/winequality-white.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ca6a09adeecd4dc07b33e765baa4ea82820fe37"},"cell_type":"code","source":"data.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   fixed acidity  volatile acidity   ...     alcohol  quality\n0            7.0              0.27   ...         8.8        6\n1            6.3              0.30   ...         9.5        6\n2            8.1              0.28   ...        10.1        6\n3            7.2              0.23   ...         9.9        6\n4            7.2              0.23   ...         9.9        6\n\n[5 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.0</td>\n      <td>0.27</td>\n      <td>0.36</td>\n      <td>20.7</td>\n      <td>0.045</td>\n      <td>45.0</td>\n      <td>170.0</td>\n      <td>1.0010</td>\n      <td>3.00</td>\n      <td>0.45</td>\n      <td>8.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.3</td>\n      <td>0.30</td>\n      <td>0.34</td>\n      <td>1.6</td>\n      <td>0.049</td>\n      <td>14.0</td>\n      <td>132.0</td>\n      <td>0.9940</td>\n      <td>3.30</td>\n      <td>0.49</td>\n      <td>9.5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.1</td>\n      <td>0.28</td>\n      <td>0.40</td>\n      <td>6.9</td>\n      <td>0.050</td>\n      <td>30.0</td>\n      <td>97.0</td>\n      <td>0.9951</td>\n      <td>3.26</td>\n      <td>0.44</td>\n      <td>10.1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.2</td>\n      <td>0.23</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.9956</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.2</td>\n      <td>0.23</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.9956</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"8567888d41488b52f8b2d3dff80bd2d16c3df07d"},"cell_type":"code","source":"data.info()","execution_count":4,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4898 entries, 0 to 4897\nData columns (total 12 columns):\nfixed acidity           4898 non-null float64\nvolatile acidity        4898 non-null float64\ncitric acid             4898 non-null float64\nresidual sugar          4898 non-null float64\nchlorides               4898 non-null float64\nfree sulfur dioxide     4898 non-null float64\ntotal sulfur dioxide    4898 non-null float64\ndensity                 4898 non-null float64\npH                      4898 non-null float64\nsulphates               4898 non-null float64\nalcohol                 4898 non-null float64\nquality                 4898 non-null int64\ndtypes: float64(11), int64(1)\nmemory usage: 459.3 KB\n","name":"stdout"}]},{"metadata":{"_uuid":"40b24e1cbe39da5f25f6abdfa6f4dce01052eba2"},"cell_type":"markdown","source":"**Separate the target feature, split data in 7:3 proportion (30% form a holdout set, use random_state=17), and preprocess data with `StandardScaler`.**"},{"metadata":{"trusted":true,"_uuid":"22991d1fcd912df4535ec8e0dd804d9d66b336f6"},"cell_type":"code","source":"y = data['quality']\n\nX_train, X_holdout, y_train, y_holdout = train_test_split(data.drop(['quality'], axis=1), data['quality'], random_state=17,train_size=0.7 )\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_holdout_scaled = scaler.transform(X_holdout)","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"4323af0a23b5a874c7fb0fc3bcadeebefd5bdce1"},"cell_type":"markdown","source":"## Linear regression"},{"metadata":{"_uuid":"39e8d88d30226a24ea1d62cfdf849b9a9b164a3f"},"cell_type":"markdown","source":"**Train a simple linear regression model (Ordinary Least Squares).**"},{"metadata":{"trusted":true,"_uuid":"d228bb880c81ea10ad104e1f9685c8a2ee95ae97"},"cell_type":"code","source":"linreg = LinearRegression()\nlinreg.fit(X_train_scaled, y_train)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False)"},"metadata":{}}]},{"metadata":{"_uuid":"143bd8c03bc75265fe317b7163ea9992fec72a52"},"cell_type":"markdown","source":"**<font color='red'>Question 1:</font> What are mean squared errors of model predictions on train and holdout sets?**"},{"metadata":{"trusted":true,"_uuid":"546f6310409fd0cced8e9cf9b5b9b647bc519b4a"},"cell_type":"code","source":"print(\"Mean squared error (train): %.3f\" % mean_squared_error(y_train, linreg.predict(X_train_scaled)))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, linreg.predict(X_holdout_scaled)))","execution_count":7,"outputs":[{"output_type":"stream","text":"Mean squared error (train): 0.558\nMean squared error (test): 0.584\n","name":"stdout"}]},{"metadata":{"_uuid":"eb150b4956b12f57d7a4d2a868b220d56951c70d"},"cell_type":"markdown","source":"**Sort features by their influence on the target feature (wine quality). Beware that both large positive and large negative coefficients mean large influence on target. It's handy to use `pandas.DataFrame` here.**\n\n**<font color='red'>Question 2:</font> Which feature this linear regression model treats as the most influential on wine quality?**"},{"metadata":{"trusted":true,"_uuid":"00f2cd04fdee695e60a0019a095999c1b9d98ff7"},"cell_type":"code","source":"linreg_coef = pd.DataFrame(linreg.coef_, columns=['coef']) # you code here\nlinreg_coef.apply(lambda x: np.abs(x)).sort_values(by='coef',ascending=False )","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"        coef\n7   0.665720\n3   0.538164\n1   0.192260\n8   0.150036\n10  0.129533\n0   0.097822\n9   0.062053\n5   0.042180\n6   0.014304\n4   0.008127\n2   0.000183","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>coef</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>0.665720</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.538164</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.192260</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.150036</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.129533</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.097822</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.062053</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.042180</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.014304</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.008127</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000183</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"c8180a8be8a1c16db3b3a4b2f1b045360fffedb8"},"cell_type":"markdown","source":"## Lasso regression"},{"metadata":{"_uuid":"ec78a7a6489c112634ab66ee3c8a64732333b255"},"cell_type":"markdown","source":"**Train a LASSO model with $\\alpha = 0.01$ (weak regularization) and scaled data. Again, set random_state=17.**"},{"metadata":{"trusted":true,"_uuid":"c93c9f0aef5c045104cd170a415f0138ecfde280"},"cell_type":"code","source":"lasso1 = Lasso(random_state=17, alpha=0.01)\nlasso1.fit(X_train_scaled, y_train)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,\n   normalize=False, positive=False, precompute=False, random_state=17,\n   selection='cyclic', tol=0.0001, warm_start=False)"},"metadata":{}}]},{"metadata":{"_uuid":"2ebc826e15035e973f142ea14529e9ea62f0eaae"},"cell_type":"markdown","source":"**Which feature is the least informative in predicting wine quality, according to this LASSO model?**"},{"metadata":{"trusted":true,"_uuid":"a3e0123570f2bfc183e9af04fc09de4aa00a3e33"},"cell_type":"code","source":"lasso1_coef = pd.DataFrame(lasso1.coef_, columns=['lasso_coef']) # you code here\nlasso1_coef.apply(lambda x: np.abs(x)).sort_values(by='lasso_coef',ascending=False )","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"    lasso_coef\n10    0.322425\n3     0.256363\n7     0.235492\n1     0.188479\n8     0.067277\n5     0.043088\n9     0.029722\n4     0.002747\n0     0.000000\n2     0.000000\n6     0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lasso_coef</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>0.322425</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.256363</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.235492</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.188479</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.067277</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.043088</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.029722</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.002747</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"34daf26da8dc65ca9dea1390b1c990bdb1e746fe"},"cell_type":"markdown","source":"**Train LassoCV with random_state=17 to choose the best value of $\\alpha$ in 5-fold cross-validation.**"},{"metadata":{"trusted":true,"_uuid":"1261f3d8b86bf6b32a47f4fbd6421a224a32fb25"},"cell_type":"code","source":"alphas = np.logspace(-6, 2, 200)\nlasso_cv = LassoCV(alphas=alphas, random_state=17)\nlasso_cv.fit(X_train_scaled, y_train)","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"LassoCV(alphas=array([1.00000e-06, 1.09699e-06, ..., 9.11589e+01, 1.00000e+02]),\n    copy_X=True, cv='warn', eps=0.001, fit_intercept=True, max_iter=1000,\n    n_alphas=100, n_jobs=None, normalize=False, positive=False,\n    precompute='auto', random_state=17, selection='cyclic', tol=0.0001,\n    verbose=False)"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"11cfcfa256d3fadcc41c17c4a203980f43270f86"},"cell_type":"code","source":"lasso_cv.alpha_","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"0.0003739937302478798"},"metadata":{}}]},{"metadata":{"_uuid":"774659494a9e10c5880a061b77f0ad4de3f6f48c"},"cell_type":"markdown","source":"**<font color='red'>Question 3:</font> Which feature is the least informative in predicting wine quality, according to the tuned LASSO model?**"},{"metadata":{"trusted":true,"_uuid":"e48d180e412893f9b510a39edcf612d13a865dc9"},"cell_type":"code","source":"lasso_cv_coef = pd.DataFrame(lasso_cv.coef_, columns=['lasso_coef']) # you code here\nlasso_cv_coef.apply(lambda x: np.abs(x)).sort_values(by='lasso_coef' )","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"    lasso_coef\n2     0.000000\n4     0.006558\n6     0.012546\n5     0.042865\n9     0.060585\n0     0.091858\n10    0.139555\n8     0.145426\n1     0.191992\n3     0.523266\n7     0.642524","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lasso_coef</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.006558</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.012546</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.042865</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.060585</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.091858</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.139555</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.145426</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.191992</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.523266</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.642524</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"6784416717d86f9693adc016ebf2805d82e1f44f"},"cell_type":"markdown","source":"**<font color='red'>Question 4:</font> What are mean squared errors of tuned LASSO predictions on train and holdout sets?**"},{"metadata":{"trusted":true,"_uuid":"8c1e912d29500bdd01232dffb7b7b12708a61354"},"cell_type":"code","source":"print(\"Mean squared error (train): %.3f\" % mean_squared_error(y_train, lasso_cv.predict(X_train_scaled)))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, lasso_cv.predict(X_holdout_scaled)))","execution_count":14,"outputs":[{"output_type":"stream","text":"Mean squared error (train): 0.558\nMean squared error (test): 0.583\n","name":"stdout"}]},{"metadata":{"_uuid":"cece55c36b4975456ac808ed60f80c4607bce364"},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"_uuid":"2b1d919f11b7552d1fd5218469049cbceb0c6b12"},"cell_type":"markdown","source":"**Train a Random Forest with out-of-the-box parameters, setting only random_state to be 17.**"},{"metadata":{"trusted":true,"_uuid":"ef3ab441dd993dbae6326026fa0b685ecb048e43"},"cell_type":"code","source":"forest = RandomForestRegressor(random_state=17,)\nforest.fit(X_train_scaled, y_train)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n           oob_score=False, random_state=17, verbose=0, warm_start=False)"},"metadata":{}}]},{"metadata":{"_uuid":"79d151e17dda0fa3667e01f5514edc9fa471a99f"},"cell_type":"markdown","source":"**<font color='red'>Question 5:</font> What are mean squared errors of RF model on the training set, in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**"},{"metadata":{"trusted":true,"_uuid":"78cb1562e5250e2c495954ed2f2007db4e9bd4ac"},"cell_type":"code","source":"print(\"Mean squared error (train): %.3f\"  % mean_squared_error(y_train, forest.predict(X_train_scaled)))\nprint(\"Mean squared error (cv): %.3f\" % np.mean(cross_val_score(forest, X=X_train_scaled, y=y_train, scoring='neg_mean_squared_error')))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, forest.predict(X_holdout_scaled)))","execution_count":16,"outputs":[{"output_type":"stream","text":"Mean squared error (train): 0.075\nMean squared error (cv): -0.460\nMean squared error (test): 0.422\n","name":"stdout"}]},{"metadata":{"_uuid":"cbfda28eb1ad4d6d0a8b640e6bcee1a6c2a0d83a"},"cell_type":"markdown","source":"**Tune the `max_features` and `max_depth` hyperparameters with GridSearchCV and again check mean cross-validation MSE and MSE on holdout set.**"},{"metadata":{"trusted":true,"_uuid":"b8fcca3ab63a14e9ebe4e05f1b706affee19ec15"},"cell_type":"code","source":"%%time\nforest_params = {'max_depth': list(range(10, 25)), \n                 'min_samples_leaf': list(range(1, 8)),\n                 'max_features': list(range(6,12))}\n\nlocally_best_forest = GridSearchCV(forest, param_grid=forest_params, n_jobs=-1, verbose=1, cv=5)\nlocally_best_forest.fit(X_train_scaled, y_train)","execution_count":17,"outputs":[{"output_type":"stream","text":"Fitting 5 folds for each of 630 candidates, totalling 3150 fits\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.9s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   16.8s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   27.3s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   43.0s\n[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.1min\n[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  1.5min\n[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  2.0min\n","name":"stderr"},{"output_type":"stream","text":"CPU times: user 8.55 s, sys: 965 ms, total: 9.51 s\nWall time: 2min 35s\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 3150 out of 3150 | elapsed:  2.6min finished\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"daa31046bca781b63e8b08d941d270ed39cca694"},"cell_type":"code","source":"locally_best_forest.best_params_, locally_best_forest.best_score_","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"({'max_depth': 19, 'max_features': 7, 'min_samples_leaf': 1},\n 0.4465038635111042)"},"metadata":{}}]},{"metadata":{"_uuid":"f3b5f128ac9d25d6a2fe001e1b945d890e4e125a"},"cell_type":"markdown","source":"**<font color='red'>Question 6:</font> What are mean squared errors of tuned RF model in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**"},{"metadata":{"trusted":true,"_uuid":"8b1c78727baa4caa5e5de4fc99289f9c38a78eca"},"cell_type":"code","source":"%%time\nprint(\"Mean squared error (cv): %.3f\" %  np.mean(cross_val_score(locally_best_forest,verbose=1, X=X_train_scaled, y=y_train,n_jobs=-1, scoring='neg_mean_squared_error')))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, locally_best_forest.predict(X_holdout_scaled)))","execution_count":19,"outputs":[{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"Mean squared error (cv): -0.469\nMean squared error (test): 0.410\nCPU times: user 32.4 ms, sys: 2.49 ms, total: 34.9 ms\nWall time: 4min 31s\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  4.5min finished\n","name":"stderr"}]},{"metadata":{"_uuid":"2edaca791a764dcbd8c255c622046a3262c9d343"},"cell_type":"markdown","source":"**Output RF's feature importance. Again, it's nice to present it as a DataFrame.**<br>\n**<font color='red'>Question 7:</font> What is the most important feature, according to the Random Forest model?**"},{"metadata":{"trusted":true,"_uuid":"c5fc1d874ba41c152e0c1dd11eba469320a91613"},"cell_type":"code","source":"best_rf_coefs = pd.DataFrame(locally_best_forest.best_estimator_.feature_importances_, columns=['rf_coef']) # you code here\nbest_rf_coefs.apply(lambda x: np.abs(x)).sort_values(by='rf_coef' )","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"     rf_coef\n9   0.061184\n2   0.062945\n0   0.064268\n4   0.067982\n7   0.069367\n3   0.070160\n6   0.071318\n8   0.072806\n5   0.116147\n1   0.119393\n10  0.224432","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rf_coef</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>0.061184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.062945</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.064268</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.067982</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.069367</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.070160</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.071318</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.072806</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.116147</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.119393</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.224432</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"bc3c0e87a735ef74b1d1de869dd8ceae9fa42f9a"},"cell_type":"markdown","source":"**Make conclusions about the perdormance of the explored 3 models in this particular prediction task.**"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Заметно , что случайный лес переобучается намного меньше чем логит, из-за меньшей MSE на тестовых данных. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}